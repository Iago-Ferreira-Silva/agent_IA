<h1 align="center">ğŸ¤– Assistente Virtual</h1>

<p align="center">
  Um <strong>chatbot multimodelo</strong> desenvolvido em <code>Python</code> com <code>Streamlit</code> e <code>LangChain</code>, que permite conversar com diferentes LLMs (OpenAI, HuggingFace e Ollama).<br/>
  Ideal para estudos, prototipagem e integraÃ§Ã£o de modelos de linguagem em aplicaÃ§Ãµes reais.
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white"/>
  <img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white"/>
  <img src="https://img.shields.io/badge/LangChain-1C3C3C?style=for-the-badge&logo=chainlink&logoColor=white"/>
  <img src="https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white"/>
  <img src="https://img.shields.io/badge/HuggingFace-FCC624?style=for-the-badge&logo=huggingface&logoColor=black"/>
  <img src="https://img.shields.io/badge/Ollama-000000?style=for-the-badge&logo=ollama&logoColor=white"/>
</p>

***

## âœ¨ FUNCIONALIDADES:

- ğŸ’¬ Interface de chat em tempo real com **Streamlit**.  
- ğŸ”„ Suporte a mÃºltiplos backends de LLM (OpenAI, HuggingFace, Ollama).  
- âš¡ Respostas em **streaming** (quando suportado).  
- ğŸ“ HistÃ³rico de conversa persistente durante a sessÃ£o.  
- ğŸ›ï¸ ConfiguraÃ§Ã£o de **temperatura** e **mÃ¡ximo de tokens** via interface.  
- ğŸŒ Respostas em portuguÃªs (ou no idioma configurado).  

***

## ğŸ“ ESTRUTURA DE PASTAS:

```bash
agent_IA/
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”‚
â””â”€â”€ README.md

```

***

## ğŸ› ï¸ TECNOLOGIAS UTILIZADAS:

- `Python`: Linguagem principal do projeto.
- `Streamlit`: Framework para criaÃ§Ã£o da interface web.
- `LangChain`: OrquestraÃ§Ã£o de prompts e integraÃ§Ã£o com LLMs.
- `OpenAI API`: Modelos GPT (opcional).
- `Hugging Face Hub`: Modelos como Llama 3, Mistral, Falcon, Gemma.
- `Ollama`: ExecuÃ§Ã£o de modelos localmente.
- `dotenv`: Gerenciamento de variÃ¡veis de ambiente.
- `Torch`: Backend necessÃ¡rio para alguns modelos HuggingFace.

***

## ğŸš§ DIFICULDADES ENCONTRADAS:

- âš ï¸ Limite de crÃ©ditos na API da OpenAI.
- ğŸ”„ DiferenÃ§as entre modelos que suportam streaming e os que nÃ£o suportam.
- ğŸ§© Ajuste de prompts para compatibilidade entre backends diferentes.
- ğŸ› ï¸ Tratamento de erros de API e mensagens amigÃ¡veis ao usuÃ¡rio.

***

## ğŸš€ COMO RODAR O PROJETO LOCALMENTE:

### 1. Clone o repositÃ³rio:

```bash
git clone https://github.com/Iago-Ferreira-Silva/agent_IA.git
```
### 2. Acesse o diretÃ³rio do projeto:

```bash
cd agent_IA
```
### 3. Crie e ative um ambiente virtual:

```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
```

### 4. Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```
### 5. Configure suas chaves no arquivo .env:

```bash
OPENAI_API_KEY=your_openai_api_key
HUGGINGFACEHUB_API_TOKEN=your_hf_token
```

### 6. Execute a aplicaÃ§Ã£o:

```bash
streamlit run main.py
```

### 7. Acesse no navegador:

```bash
http://localhost:8501
```

***

## ğŸ“Œ STATUS DO PROJETO:
![Badge ConcluÃ­do](https://img.shields.io/static/v1?label=STATUS&message=CONCLU%C3%8DDO&color=brightgreen&style=for-the-badge)

***
